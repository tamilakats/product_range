{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "005741e4",
   "metadata": {},
   "source": [
    "## Final Project\n",
    "**By Tamila Kats**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c851ba85",
   "metadata": {},
   "source": [
    "[Tableau Dashboard](https://public.tableau.com/views/Project_Product_Range/Dashboard2?:language=en-US&:display_count=n&:origin=viz_share_link)\n",
    "\n",
    "[Presentation](https://drive.google.com/file/d/1UWvtQnUqJMVUMtdg0BaHmX93URG4X7ID/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6953ae5",
   "metadata": {},
   "source": [
    "# Product Range Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54fa237",
   "metadata": {},
   "source": [
    "We have data on sales of online store contains order number, item identifier and name, purchased quantity, price per item, order date and customer id. We are going to analyze this information to define categories of products by price, which of them often bought in big quantity, how many orders customers usually make, what groups we can form by the average check, whether demand is change from season to season, etc. We will provide recommendations for increasing sales figures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc61b3a8",
   "metadata": {},
   "source": [
    "### Table of Content:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0f4c57",
   "metadata": {},
   "source": [
    "* [ General Overview and Preprocessing](#general)\n",
    "* [Defining categories](#categories)\n",
    "  * [Study distribution of prices](#price)\n",
    "  * [Parsing of names of products](#names)\n",
    "  * [Defining proportions of regular and casual customers](#loyal)\n",
    "  * [Categorizing customers by average check](#avg)\n",
    "* [Identifying the seasonality of demand](#season)\n",
    "  * [Checking for general increasing of demand by season](#season_gen)\n",
    "  * [Checking for special interest to certain categories of products by season](#season_cat)\n",
    "* [Analysis of carts](#carts)\n",
    "  * [Define products that often bought together](#together)\n",
    "  * [Define which products often bought in big amount](#bigamount)\n",
    "* [Analysis of canceled orders](#canceled)\n",
    "* [Testing statistical hypotheses](#hypotheses)\n",
    "  * [If there is a statistically significant difference between revenue from small products that were bought in big amounts and big expensive products that bought one at a time?](#first)\n",
    "  * [If there is a statistically significant difference between revenue in summer and winter?](#second)\n",
    "* [Overall conclusion and recommendations](#overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9fb18e",
   "metadata": {},
   "source": [
    "## General Overview and Preprocessing <a class=\"anchor\" id=\"general\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe6f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import mannwhitneyu\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd5f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for text preprocessing\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords') \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "#from nltk.tokenize import RegexpTokenizer\n",
    "#nltk.download('wordnet') \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "#! pip install mlxtend \n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba327de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ecommerce_data = pd.read_csv('/Users/tamilaz/Downloads/ecommerce_dataset_us.csv', sep='\\t')\n",
    "except:\n",
    "    ecommerce_data = pd.read_csv('/datasets/ecommerce_dataset_us.csv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764934f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cfbd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9c1ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing names of columns to more convenient\n",
    "ecommerce_data.columns=['invoice_no', 'stock_code', 'description', \n",
    "                        'quantity', 'invoice_date', 'unit_price', 'customer_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bee36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values\n",
    "ecommerce_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ce70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for percentage of null values in column 'description'\n",
    "print('Percent of null values in column \"description\": {:.2f}%'.format(\n",
    "    ecommerce_data['description'].isnull().sum()*100 / len(ecommerce_data)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a77630",
   "metadata": {},
   "source": [
    "We will remove these null values, because without description we couldn't analyze these products and 0.27% is not significant piece of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8654d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping rows with null values\n",
    "ecommerce_data.dropna(subset=['description'], inplace=True)\n",
    "ecommerce_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for percentage of null values in column 'customer_id'\n",
    "print('Percent of null values in column \"customer_id\": {:.2f}%'.format(\n",
    "    ecommerce_data['customer_id'].isnull().sum()*100 / len(ecommerce_data)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af410b",
   "metadata": {},
   "source": [
    "There is a significant part of a dataset with null values in column 'customer_id'. We can't remove it and the goal of our analysis is products and not customers so we will leave all this rows, but fill null with value 'unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7875bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling NA with 'unknown'\n",
    "ecommerce_data['customer_id'] = ecommerce_data['customer_id'].fillna('unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45344cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicates\n",
    "print('Number of duplicates is {}.'.format(ecommerce_data.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b6725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for percentage of duplicates for all data\n",
    "print('Share of duplicates in the dataset is {:.2f}%.'.format(\n",
    "    ecommerce_data.duplicated().sum()*100 / len(ecommerce_data)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d1f9eb",
   "metadata": {},
   "source": [
    "We will remove the duplicates because it's share is not significant and there are most likely mistakes of order registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc36540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the duplicates \n",
    "ecommerce_data = ecommerce_data.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46160c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing datatypes to correct ones\n",
    "ecommerce_data['quantity'] = pd.to_numeric(ecommerce_data['quantity'], downcast='unsigned')\n",
    "ecommerce_data['invoice_date'] = ecommerce_data['invoice_date'].astype('datetime64')\n",
    "ecommerce_data['unit_price'] = pd.to_numeric(ecommerce_data['unit_price'], downcast='float')\n",
    "\n",
    "ecommerce_data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfef8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the date from invoice_date for more convenient further analysis\n",
    "ecommerce_data['invoice_date'] = ecommerce_data['invoice_date'].dt.date\n",
    "ecommerce_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23034b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_data['invoice_date'] = pd.to_datetime(ecommerce_data['invoice_date'], format='%Y-%m-%d')\n",
    "ecommerce_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b9570",
   "metadata": {},
   "source": [
    "We want to check values of column 'stock_code' on special/strange values(non-numeric):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caab7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for all non-numeric values of stock code\n",
    "codes = ecommerce_data[ecommerce_data['stock_code'].str.contains('^[a-zA-Z]+') == True]\n",
    "codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking what kinds of special codes there are \n",
    "print('Non-numeric/irrelevant values in column \"stock_code\": {}'.format(\n",
    "    codes['stock_code'].unique()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d0f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the percentage  of rows with special/strange codes\n",
    "print('Share of rows with irrelevant values in column \"stock_code\": {:.2f}%'.format(\n",
    "    len(codes) * 100/ len(ecommerce_data)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf589e6",
   "metadata": {},
   "source": [
    "We'll remove rows with all special stock codes because they are not relevant for our analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing irrelevant values\n",
    "ecommerce_data = ecommerce_data.drop(codes.index).reset_index(drop=True)\n",
    "ecommerce_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55883d3",
   "metadata": {},
   "source": [
    "We want to check the number of canceled orders(values in column \"invoice_no\" starts with \"C\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ff0039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the number of cancelations\n",
    "canceled = ecommerce_data.loc[ecommerce_data['invoice_no'].str.startswith('C'), 'invoice_no']\n",
    "print('Number of canceled orders is {}.'.format(canceled.count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6707a222",
   "metadata": {},
   "source": [
    "We will split our dataset on two: one for all orders and second only for canceled. We will analyze them separately. Our purpose is to analyze what products are popular and profitable so we want to analyze all of them even if in the end the order was canceled for some reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b9a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new df with orders without cancelations\n",
    "ecommerce_data_orders= ecommerce_data.drop(ecommerce_data[ecommerce_data['invoice_no'].str.startswith('C')].index).reset_index(drop=True)\n",
    "ecommerce_data_orders.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8becb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a df with canceled orders\n",
    "ecommerce_data_canceled= ecommerce_data[ecommerce_data['invoice_no'].str.startswith('C')]\n",
    "ecommerce_data_canceled.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90afefb",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce58549b",
   "metadata": {},
   "source": [
    "We got a dataset with 541909 entries that contain information about orders made in the store: order number and date, identifier and name of the product, purchased quantity, price per unit, customer id. \n",
    "\n",
    "We changed all column names to more convenient and changed datatypes to correct ones. We found null values in column ‘description’ and removed them because its share was insignificant - 0.27% and it is impossible to analyze products without names. Null values in column ‘customer_id’ were filled with value ‘unknown’ because we want to have as many as possible ordered products for analysis and this is a significant part of the dataset - 24.72%. We removed all duplicates,  there were 0.97%. \n",
    "\n",
    "We also cleaned the data from irrelevant values in column ‘stock_code’, there were non-numeric special and strange codes that were not needed for our analysis.  Finally, we split our dataset into two - one with all orders and the second only with canceled to analyze them separately afterward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ee4ff1",
   "metadata": {},
   "source": [
    "## Categorizing of products and customers <a class=\"anchor\" id=\"categories\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef861266",
   "metadata": {},
   "source": [
    "At this stage, we are going to define categories of products by their names and prices, and of customers by their regularity and average check.\n",
    "\n",
    "At first we will check general numbers: total amount of orders, unique products and customers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the total number of orders(with cancellations)\n",
    "print('Total number of orders: {}.'.format(\n",
    "    ecommerce_data_orders['invoice_no'].nunique()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eff1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the number of disctinct products that were bought\n",
    "print('Number of unique product names: {}.'.format(\n",
    "    ecommerce_data_orders['stock_code'].nunique()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3122c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the number of customers\n",
    "print('Number of customers: {}.'.format(\n",
    "    ecommerce_data_orders['customer_id'].nunique()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ee2e2",
   "metadata": {},
   "source": [
    "Now we will define categories of products by price: <a class=\"anchor\" id=\"price\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0433dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_data_orders['unit_price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072e93dd",
   "metadata": {},
   "source": [
    "Min price is 0, it is most likely a mistake, anomaly that we should check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1242b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking products with price 0\n",
    "ecommerce_data_orders[ecommerce_data_orders['unit_price']== 0].sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a1f190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the percentage of units with price 0\n",
    "print('The percentage of values 0 in column \"unit_price\" - {:.1f}%.'.format(\n",
    "    len(ecommerce_data_orders[ecommerce_data_orders['unit_price']== 0]) *100 / len(ecommerce_data_orders)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122dd0d3",
   "metadata": {},
   "source": [
    "There are strange descriptions and quantities, many unknown customers and it's only 0.2% of the dataset so we will remove these rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dac83c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing rows with irrelevant data\n",
    "ecommerce_data_orders = ecommerce_data_orders.drop(ecommerce_data_orders[ecommerce_data_orders['unit_price']== 0].index).reset_index(drop=True)\n",
    "ecommerce_data_orders.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110b3d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_data_orders['unit_price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a04add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a histogram of distribution of prices\n",
    "fig=px.histogram(ecommerce_data_orders, x='unit_price', title='Distribution of prices')\n",
    "fig.update_layout(xaxis_title='Price', yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba413024",
   "metadata": {},
   "source": [
    "We want to categorize bought products by price for cheap and expensive. We see that most of a products are very cheap around 0 and there are some outliers with the biggest value 649.5. First of all we will calculate percentiles to try to make a categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f577af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating 0.25 quantile to find the border of low prices\n",
    "print('The lower quantile is {:.2f}'.format(\n",
    "    ecommerce_data_orders['unit_price'].quantile(0.25)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fee904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating 0.75 quantile to find the border of high prices\n",
    "print('The upper quantile is {:.2f}'.format(\n",
    "    ecommerce_data_orders['unit_price'].quantile(0.75)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c652d6cc",
   "metadata": {},
   "source": [
    "These values are too small to use them for making useful categories so we will try to work with histograms to do it visually.\n",
    "\n",
    "On the previous histogram we saw that only few products cost more than 100 so we will build a new histogram without these outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca2f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a histgram with values less than 100\n",
    "fig=px.histogram(ecommerce_data_orders[ecommerce_data_orders['unit_price'] < 100], x='unit_price', title='Distribution of prices')\n",
    "fig.update_layout(xaxis_title='Price', yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce671d2",
   "metadata": {},
   "source": [
    "Here we see that between 20 and 100 are not many values so this wiil be our second border:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a histogram with values less than 20\n",
    "fig=px.histogram(ecommerce_data_orders[ecommerce_data_orders['unit_price'] < 20], x='unit_price', title='Distribution of prices')\n",
    "fig.update_layout(xaxis_title='Price', yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cac150",
   "metadata": {},
   "source": [
    "Finally we see that price of most of the products is between 0-5 so this is our next border. Also we can notice here that the most common range of prices is 1.63-1.67 and after 2.12 there is quite significant fall, so we will use this value as our last border.\n",
    "\n",
    "Final product categories by price: 'very expensive' - 650-20, 'expensive'- 20-5, 'cheap' - 5-2.13, 'very cheap' - 2.12-0.04. \n",
    "\n",
    "We build a function to assign appropriate categories to the products by adding of a new column to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9828c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a function for splitting products by categories\n",
    "def price_category(price):\n",
    "    if price <= 2.12:\n",
    "        return 'very cheap'\n",
    "    if 2 <= price <= 5:\n",
    "        return 'cheap'\n",
    "    if 5 <= price <= 20:\n",
    "        return 'expensive'\n",
    "    return 'very expensive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071b1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying a function and creating new column in df\n",
    "ecommerce_data_orders['price_category'] = ecommerce_data_orders['unit_price'].apply(price_category)\n",
    "ecommerce_data_orders.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a73b2f9",
   "metadata": {},
   "source": [
    "Now we are going to define categories of products by their names. At first we will clean descriptions and make them more universal for easier searching of keywords: <a class=\"anchor\" id=\"names\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating a list of stop words \n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de3c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]\n",
    "\n",
    "for i in range(0, 522504):\n",
    "    #Remove punctuations\n",
    "    text = re.sub('[^a-zA-Z]', ' ', ecommerce_data_orders['description'][i])\n",
    "    \n",
    "    text= ecommerce_data_orders['description'][i]\n",
    "    #Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    #Convert to list from string\n",
    "    text = text.split()\n",
    "    \n",
    "    #Stemming\n",
    "    ps=PorterStemmer()\n",
    "    #Lemmatisation\n",
    "    lem = WordNetLemmatizer()\n",
    "    text = [lem.lemmatize(word) for word in text if not word in  \n",
    "            stop_words] \n",
    "    text = \" \".join(text)\n",
    "    result.append(text)\n",
    "    \n",
    "ecommerce_data_orders['description_cleaned'] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8514c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining common words in clean description to define popular keywords\n",
    "count_words = pd.Series(' '.join(ecommerce_data_orders['description_cleaned'].unique()).split()).value_counts()[240:280]\n",
    "#count_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61954fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking names of products with particular keyword before adding to the function\n",
    "ecommerce_data_orders[ecommerce_data_orders['description_cleaned'].str.contains('crayon') == True]['description'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a function for categorizing products\n",
    "def categorize(keyword):\n",
    "    if ('food cover' in keyword) or ('bowl' in keyword) or \\\n",
    "    ('bottle' in keyword) or ('mug' in keyword) or ('cup' in keyword) or \\\n",
    "    ('jar' in keyword) or ('cutlery' in keyword) or ('tray' in keyword) or \\\n",
    "    ('plate' in keyword) or ('dish' in keyword) or ('apron' in keyword) or \\\n",
    "    ('towel' in keyword) or ('cake case' in keyword) or ('cake tin' in keyword) or \\\n",
    "    ('mould' in keyword) or ('tea' in keyword) or ('baking' in keyword) or \\\n",
    "    ('lunch box' in keyword) or ('spoon' in keyword) or ('recipe box' in keyword) or \\\n",
    "    ('cutter' in keyword) or ('saucer' in keyword) or ('kitchen scale' in keyword) or \\\n",
    "    ('snack box' in keyword) or ('jam' in keyword) or ('spice tin' in keyword) or \\\n",
    "    ('chopping board' in keyword) or ('oven glove' in keyword):\n",
    "        category= 'kitchen'\n",
    "    elif ('necklace' in keyword) or ('bracelet' in keyword) or \\\n",
    "    ('earring' in keyword) or ('hair' in keyword) or ('key ring' in keyword) or \\\n",
    "    ('phone charm' in keyword) or ('bag charm' in keyword) or ('jewel' in keyword) or \\\n",
    "    ('brooch' in keyword) or ('trinket box' in keyword):\n",
    "        category= 'accessories'\n",
    "    elif ('drawer knob' in keyword) or ('metal sign' in keyword) or \\\n",
    "    ('doormat' in keyword) or ('doorstop' in keyword) or ('hook' in keyword) or \\\n",
    "    ('hanger' in keyword) or ('door sign' in keyword) or ('coat rack' in keyword) :\n",
    "        category= 'hallway'\n",
    "    elif ('paper lantern' in keyword) or ('paper bell' in keyword) or \\\n",
    "    ('paper ball' in keyword) or ('paper chain' in keyword) or ('garland' in keyword) or \\\n",
    "    ('bunting' in keyword) or ('wrap' in keyword) or \\\n",
    "    ('ribbon' in keyword) or ('christmas' in keyword) or \\\n",
    "    ('easter' in keyword) or ('napkin' in keyword) or ('tissue' in keyword) or \\\n",
    "    ('doily' in keyword) or ('cake stand' in keyword) or ('cakestand' in keyword) or \\\n",
    "    ('paper plates' in keyword) or ('balloon' in keyword) or ('party' in keyword) or ('bauble' in keyword) or \\\n",
    "    ('nesting' in keyword):\n",
    "        category='party'\n",
    "    elif ('notebook' in keyword) or ('sticker' in keyword) or \\\n",
    "    ('pencil' in keyword) or ('birthday card' in keyword) or ('greeting card' in keyword) or \\\n",
    "    ('set 10 card' in keyword) or ('passport cover' in keyword) or ('sketchbook' in keyword) or \\\n",
    "    ('memo board' in keyword):\n",
    "        category='cabinet'\n",
    "    elif ('light' in keyword) or ('candle' in keyword) or \\\n",
    "    ('decoration' in keyword) or ('holder' in keyword) or \\\n",
    "    ('clock' in keyword) or ('cushion cover' in keyword) or \\\n",
    "    ('cushion' in keyword) or ('block' in keyword) or \\\n",
    "    ('frame' in keyword) or ('magnet' in keyword) or \\\n",
    "    ('incense' in keyword) or ('wall art' in keyword) or ('ornament' in keyword) or \\\n",
    "    ('heart wicker' in keyword) or ('vintage billboard' in keyword) :\n",
    "        category='home decoration'\n",
    "    elif ('bag' in keyword) or ('purse' in keyword) or \\\n",
    "    ('wallet' in keyword) or ('hamper' in keyword) or \\\n",
    "    ('card holder' in keyword) or ('shopper' in keyword) :\n",
    "        category='bags'\n",
    "    elif 'bathroom' in keyword:\n",
    "        category='bathroom'\n",
    "    elif ('garden' in keyword) or ('umbrella' in keyword) or \\\n",
    "    ('parasol' in keyword):\n",
    "        category='garden'\n",
    "    elif ('toy' in keyword) or ('playing card' in keyword) or \\\n",
    "    ('slate' in keyword) or ('snap card' in keyword) or ('harmonica' in keyword) or \\\n",
    "    ('mouse' in keyword) or ('nancy' in keyword) or ('domino' in keyword) or \\\n",
    "    ('sewing kit' in keyword) or ('dollcraft' in keyword) or ('foxglove' in keyword) or \\\n",
    "    ('feltcraft doll' in keyword) or ('feltcraft princess' in keyword):\n",
    "        category='toys and hobbies'\n",
    "    else:\n",
    "        category='other'\n",
    "        \n",
    "    return category\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b624728",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#applying a function\n",
    "ecommerce_data_orders['category'] = ecommerce_data_orders['description_cleaned'].apply(categorize)\n",
    "ecommerce_data_orders['category'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b180bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_data_orders.groupby('category')['description_cleaned'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf94851",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_data_orders[ecommerce_data_orders['category'] == 'other']['description_cleaned'].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf11ed2",
   "metadata": {},
   "source": [
    "We categorized all products on 10 categories and products with less common keywords make a category 'other'. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a69f2",
   "metadata": {},
   "source": [
    "Now we are going to analyze number of orders per customer - if there are many customers that buy frequently? What amount of orders is common and what is big? On which categories could we divide customers by number of orders they made? <a class=\"anchor\" id=\"loyal\"></a>\n",
    "\n",
    "We start with calculating of number of orders per customer, then analyze its distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdae4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the number of orders per customer\n",
    "num_orders_per_customer=ecommerce_data_orders.groupby('customer_id')['invoice_no'].nunique().reset_index()\n",
    "num_orders_per_customer.drop(num_orders_per_customer[num_orders_per_customer['customer_id'] == 'unknown'].index, inplace=True)\n",
    "num_orders_per_customer = num_orders_per_customer.rename(columns={'invoice_no': 'orders_num'})\n",
    "num_orders_per_customer.sort_values(by='orders_num',ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b84796",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting statistical data \n",
    "num_orders_per_customer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3795cef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating 95th quantile\n",
    "print('95%: {:.1f}'.format(num_orders_per_customer['orders_num'].quantile(0.95)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c0d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a histogram of distribution of number of orders per customer\n",
    "fig=px.histogram(num_orders_per_customer,\n",
    "                 x='orders_num', title='Distribution of orders per customer')\n",
    "fig.update_layout(xaxis_title='Number of orders', yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b1d173",
   "metadata": {},
   "source": [
    "It seems that the most common number of orders is less than 28 and after there are significant outliers. We recognize them as anomaly amount of orders and cut them to build more informative histogram to see differences between smaller numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad10baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a histogram without significant outliers\n",
    "fig=px.histogram(num_orders_per_customer[num_orders_per_customer['orders_num'] < 29],\n",
    "                 x='orders_num', title='Distribution of orders per customer')\n",
    "fig.update_layout(xaxis_title='Number of orders', yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f833a2",
   "metadata": {},
   "source": [
    "The most common number of orders customers made is 1 - 1505, also many customers ordered 2 times - 831. 3-4 orders are also quite popular cases and more than 5 are less, but still there is significant number of customers that ordered up to 15 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f880fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the number of casual customers that made only 1 order\n",
    "print('Number of casual customers: {}'.format(\n",
    "    num_orders_per_customer[num_orders_per_customer['orders_num'] ==1]['customer_id'].count()\n",
    "))\n",
    "print('Percentage of casual customers: {:.2f}%'.format(\n",
    "    num_orders_per_customer[num_orders_per_customer['orders_num'] ==1]['customer_id'].count() / \n",
    "    ecommerce_data_orders['customer_id'].nunique() * 100\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0633e4ef",
   "metadata": {},
   "source": [
    "Thus, we found out that there are quite many casual customers (made only 1 order) - 1505 - 34.72% of all customers, but there are much more loyal customers that made 2 and more orders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0280fe33",
   "metadata": {},
   "source": [
    "Now we will categorize customers by average check. We will calculate total price of purchased product, total size of each order, average check per customer and define what average sum of order is most common, how many customers make small and big orders. We start with calculating of total price of purchased product: <a class=\"anchor\" id=\"avg\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151be5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the total price of each product\n",
    "ecommerce_data_orders['total_price'] = ecommerce_data_orders['unit_price'] * ecommerce_data_orders['quantity']\n",
    "ecommerce_data_orders = ecommerce_data_orders.round({'total_price': 2})\n",
    "ecommerce_data_orders.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae93bb5",
   "metadata": {},
   "source": [
    "Now we can calculate total size of order per customer. We'll also remove 'unknown' customers on this step because these values will corrupt our further analysis of customers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c918849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating total sum of the order per customer\n",
    "total_order=ecommerce_data_orders.groupby(['customer_id', 'invoice_no'])['total_price'].sum().reset_index()\n",
    "total_order.drop(total_order[total_order['customer_id'] == 'unknown'].index, inplace=True)\n",
    "total_order = total_order.rename(columns={'total_price': 'total_sum'})\n",
    "total_order = total_order.sort_values(by='total_sum', ascending=False)\n",
    "total_order.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117bdb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the average check per customer\n",
    "avg_check=total_order.groupby('customer_id')['total_sum'].mean().reset_index()\n",
    "avg_check = avg_check.rename(columns={'total_sum': 'avg_check'})\n",
    "avg_check = avg_check.sort_values(by='avg_check', ascending=False)\n",
    "avg_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d91b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_check['avg_check'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339974c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a histogram of distribution of average checks\n",
    "fig=px.histogram(avg_check, x='avg_check', title='Distribution of average checks')\n",
    "fig.update_layout(xaxis_title='Average check', yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c233b20",
   "metadata": {},
   "source": [
    "The majority of the values are under 5000 and many close to 0, there are some significant outliers that we will straight away classificate as big orders and cut them to build more informative histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41194c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a histogram with values less than 5000\n",
    "fig=px.histogram(avg_check[avg_check['avg_check'] < 5000], x='avg_check', title='Distribution of average checks')\n",
    "fig.update_layout(xaxis_title='Average check', yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea7a9e",
   "metadata": {},
   "source": [
    "This histogram is more convenient to analysis: we see here that quite many customers spent in average up to 350 and also significant amount spent 350-800 that can form two groups of customers. There is less significant amount of buyers that spent 800-1000 and after there are outliers so we will group them together to one more category.\n",
    "\n",
    "In the end we have 3 categories of customers by average check: 1 - 3.75-350, 2 - 350-800, 3 - 800-85000.(This order because of number of customers in categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0cb9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function to split customers by the avg check\n",
    "def avg_check_category(check):\n",
    "    if check >= 800:\n",
    "        return '3'\n",
    "    if 350 <= check <= 800:\n",
    "        return '2'\n",
    "    else:\n",
    "        return '1'\n",
    "\n",
    "avg_check['customer_category'] = avg_check['avg_check'].apply(avg_check_category)\n",
    "avg_check.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fddf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating number of customers in each category\n",
    "print('Number of customers in each category: ')\n",
    "print('{}'.format(avg_check['customer_category'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028c2d5",
   "metadata": {},
   "source": [
    "The first category - customers with the small average check - is the biggest, there are twice more customers as in the second and third is very tiny. So we can conclude that more common to make small orders, but also important to notice these huge average checks of the third group. \n",
    "\n",
    "We can also check if there is a tendency to make big orders among customers that make many orders(loyal customers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d7dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge num_orders with avg_check\n",
    "customers= avg_check.merge(num_orders_per_customer, left_on='customer_id', right_on='customer_id')\n",
    "customers.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31272dc3",
   "metadata": {},
   "source": [
    "Good way to define relation between number of made orders and size of average check is building a scatterplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad478f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a scatterplot\n",
    "fig=px.scatter(customers, x='orders_num', y='avg_check', \n",
    "               color='customer_category', title='Relation between number of orders and average check',\n",
    "               labels={\n",
    "                   'orders_num' : 'Number of orders',\n",
    "                   'avg_check' : 'Average check',\n",
    "                   'customer_category' : 'Category'\n",
    "               }             \n",
    "              )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466a9d9d",
   "metadata": {},
   "source": [
    "There are no such relation that customers that made many orders made big orders. There are also cases of big amount of orders and small average check (1 category) and significantly higher avg check and not many orders (3). There are also some outliers from all 3 categories that only confirm that there is no such relation. \n",
    "\n",
    "We will calculate a correlation between these columns to make sure that our conclusion is right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccec420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating a correlation between num of orders and avg check\n",
    "print('Correlation between average checks and number of orders is {}.'.format(\n",
    "    customers['avg_check'].corr(customers['orders_num']).round(3)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7384b4de",
   "metadata": {},
   "source": [
    "There is no relation between number of made orders and size of average check."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9631b8e2",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7a6a1c",
   "metadata": {},
   "source": [
    "In this section, we categorized products and customers. We defined 4 categories of products by price using histograms:  'very cheap' - 0.04-2.12, 'cheap' - 2.13 - 5,  'expensive'- 5-20,  ‘very expensive' - 20-650. After that we defined categories of products by keywords: cleaned descriptions from digits and ‘stop words’, defined the most popular keywords, and wrote a function to split products by categories - ‘accessories’, ‘bags’, ‘bathroom’, ‘cabinet’, ‘garden’, ‘hallway’, ‘home decoration’, ‘kitchen’, ‘party’, ‘toys and hobbies’ and ‘other’. We also analyzed the number of orders per customer and defined that the most common number is 1-almost 35% of all customers are casual,but there are many regular customers that made 2 and more orders. \n",
    "\n",
    "We also divided customers into 3 categories by the average check - 1- 3.75-350, 2- 350-800, and 3 - 800-85000. The first category is the biggest, there are twice more customers as in the second and third is very tiny. So we can conclude that more common to make small orders, but also important to notice these huge average checks of the third group. We checked if there is a tendency among customers who made many orders to make big orders and there is no such."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ec9e48",
   "metadata": {},
   "source": [
    "## Analysis of seasonality of demand <a class=\"anchor\" id=\"season\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863be154",
   "metadata": {},
   "source": [
    "In this section we will check seasonal changes of demand (number of orders): <a class=\"anchor\" id=\"season_gen\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3470601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the number of orders per day\n",
    "season_demand=ecommerce_data_orders.groupby('invoice_date')['invoice_no'].count().reset_index()\n",
    "season_demand = season_demand.rename(columns={'invoice_no': 'orders_num'})\n",
    "season_demand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1070cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a lineplot for demand by season\n",
    "fig = px.line(season_demand, x='invoice_date', y='orders_num', title = 'Demand by season')\n",
    "fig.update_layout(xaxis_title='Date',yaxis_title= 'Orders')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8224be41",
   "metadata": {},
   "source": [
    "Demand trends are stable throughout the period from January until November with two notable peaks - 16/04 and 28/08, it starts to increase at the beginning of November and reach the maximum value in 3/12(4/12 and 15/12 in 2018 are also busy days). It makes sense to assume that these peaks are related to the holidays - Easter and Christmas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e557d",
   "metadata": {},
   "source": [
    "Now we'll check seasonality of demand by category of product: <a class=\"anchor\" id=\"season_cat\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b76273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting month from invoice_date\n",
    "ecommerce_data_orders['month']=ecommerce_data_orders['invoice_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping by month and category\n",
    "season_demand_category=ecommerce_data_orders.groupby(['month', 'category'])['invoice_no'].count().reset_index()\n",
    "season_demand_category = season_demand_category.rename(columns={'invoice_no': 'orders_num'})\n",
    "season_demand_category.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d72eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a histogram of demand by season\n",
    "fig = px.bar(season_demand_category, x='month', y='orders_num', color= 'category', title = 'Demand by season')\n",
    "fig.update_layout(xaxis_title='Date',yaxis_title= 'Orders')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed26458",
   "metadata": {},
   "source": [
    "November is the most active month, we see significant increase of orders of products almost of all categories - 'party', 'other' and 'kitchen' and 'home decoration' at most. October and December are also quite active months with some differences in popularity of categories('home decoration' and 'party' became less popular in December). Throughout the rest of the year trends of demand by category are about the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1447da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining dfs by season\n",
    "demand_winter = ecommerce_data_orders[(ecommerce_data_orders['invoice_date'] >= '2018-12-01') & (ecommerce_data_orders['invoice_date'] < '2019-03-01')]\n",
    "demand_summer = ecommerce_data_orders[(ecommerce_data_orders['invoice_date'] >= '2019-06-01') & (ecommerce_data_orders['invoice_date'] < '2019-09-01')]\n",
    "demand_spring = ecommerce_data_orders[(ecommerce_data_orders['invoice_date'] >= '2019-03-01') & (ecommerce_data_orders['invoice_date'] < '2019-06-01')]\n",
    "demand_autumn = ecommerce_data_orders[(ecommerce_data_orders['invoice_date'] >= '2019-09-01') & (ecommerce_data_orders['invoice_date'] < '2019-12-01')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d792459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the most popular products in winter\n",
    "demand_winter['description_cleaned'].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbd20c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the most popular products in summer\n",
    "demand_summer['description_cleaned'].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d66fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the most popular products in spring\n",
    "demand_spring['description_cleaned'].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132e8e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the most popular products in autumn\n",
    "demand_autumn['description_cleaned'].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d4a12e",
   "metadata": {},
   "source": [
    "Popular products definitely differ from season to season. We can notice the pattern of huge popularity of jumbo and lunch bags and buntings in summer, in spring bags are also quite popular, in autumn customers buy things that relate to christmas, in winter there is no clear pattern but there are many orders of things for home decorating and kitchen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c858c8d8",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e48b790",
   "metadata": {},
   "source": [
    "At this stage, we analyzed the seasonality of demand. We found out that demand trends are stable almost all year with a peak in April and increasing in November that seems to relate to the holidays -  Easter and Christmas. Analysis of seasonality changes of the popularity of certain categories of products shows that throughout the year it’s quite stable with increasing in October-November, but for categories it’s proportional. We also checked the popularity of certain products by season and found few patterns for seasons- in summer jambo and lunch bags are at the top of popular goods, also buntings, in spring such bags are popular too, in autumn customers already buy things related to Christmas and in winter more home decorations and kitchen stuff. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f259c2",
   "metadata": {},
   "source": [
    "## Analysis of carts <a class=\"anchor\" id=\"carts\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6c4479",
   "metadata": {},
   "source": [
    "Defining products that often bought together. We are going to use the Apriori algorithm, firstly prepared the data for it: <a class=\"anchor\" id=\"together\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a8d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a basket \n",
    "basket=(ecommerce_data_orders\n",
    "        .groupby(['invoice_no','description_cleaned'])['quantity']\n",
    "        .sum().unstack().reset_index().fillna(0)\n",
    "        .set_index('invoice_no')\n",
    "       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08051eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "basket.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6873340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting values to 0 and 1\n",
    "def convert(num):\n",
    "    if num <=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "basket_prepared=basket.applymap(convert)\n",
    "#basket_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e81ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "frq_items = apriori(basket_prepared, min_support = 0.02, use_colnames = True)\n",
    " \n",
    "# Collecting the inferred rules in a dataframe\n",
    "rules = association_rules(frq_items, metric =\"lift\", min_threshold = 1)\n",
    "rules = rules.sort_values(['confidence', 'lift'], ascending =[False, False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a17d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 1)\n",
    "rules=rules[['antecedents','consequents', 'support', 'confidence', 'lift']].round(3)\n",
    "#rules.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a78061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64386714",
   "metadata": {},
   "source": [
    "Detected combinations of goods that are often bought together are mostly two (or more) kinds of the same products that differ by color or design. There are very few examples at the top of the list of combinations of different products, such as cake stand tier and teacup saucer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd0ad68",
   "metadata": {},
   "source": [
    "Now we are going to define what products are often bought in big amounts. We will check products of what price category are more popular for buying in several copies. <a class=\"anchor\" id=\"bigamount\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e0d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting statistics about 'very cheap' category\n",
    "ecommerce_data_orders[ecommerce_data_orders['price_category'] == 'very cheap'][['quantity','total_price']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe7705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating 95th quantile because max value is anomalous\n",
    "print('95%: {}'.format(\n",
    "    ecommerce_data_orders[ecommerce_data_orders['price_category'] == 'very cheap']['quantity'].quantile(0.95)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb3a246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a histogram of distribution of quantity of very cheap products\n",
    "fig=px.histogram(ecommerce_data_orders[(ecommerce_data_orders['price_category'] == 'very cheap') & (ecommerce_data_orders['quantity'] < 100)], x='quantity', title='Distribution of quantity of very cheap products')\n",
    "fig.update_layout(xaxis_title='Quantity', yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3851d7",
   "metadata": {},
   "source": [
    "There are a lot of sold very cheap products - 280011, many of them were bought in a single copy, but more in few. The most common quantity is 12. There are also anomalous outliers - after 95th quantile that equal to 48 units there are much more up to 80995. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f4dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking statisctics for cheap products\n",
    "ecommerce_data_orders[ecommerce_data_orders['price_category'] == 'cheap']['quantity'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb57d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a histogram of distribution of quantity of cheap products\n",
    "fig=px.histogram(ecommerce_data_orders[(ecommerce_data_orders['price_category'] == 'cheap') & (ecommerce_data_orders['quantity'] < 100)], \n",
    "                 x='quantity', \n",
    "                 title='Distribution of quantity of cheap products')\n",
    "fig.update_layout(xaxis_title='Quantity', yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0855434a",
   "metadata": {},
   "source": [
    "There are significantly less sold products in this category - by ~130000. Outliers also less significant- max quantity is 1930. The most common quantity is 1 and the next value after it less than twice. Significant number of goods were sold in 6 copies, rest quantities are much less common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa10d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking statistics of axpensive goods\n",
    "ecommerce_data_orders[ecommerce_data_orders['price_category'] == 'expensive']['quantity'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfab356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a histogram of distribution of quantity of expensive products\n",
    "fig=px.histogram(ecommerce_data_orders[(ecommerce_data_orders['price_category'] == 'expensive') & (ecommerce_data_orders['quantity'] < 100)],\n",
    "                 x='quantity', \n",
    "                 title='Distribution of quantity of expensive products')\n",
    "fig.update_layout(xaxis_title='Quantity', yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bdc00e",
   "metadata": {},
   "source": [
    "There are two times less sold products in this category than in previous. The most common quantity is 1, the 2d is 2 and these more than half of all sold products in this category. Maximum value also smaller - 1412. This is less common case to buy many units of products of this category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a31690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting statistics on the 'very expensive' category\n",
    "ecommerce_data_orders[ecommerce_data_orders['price_category'] == 'very expensive']['quantity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1516151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a histogram of distribution of quantity of very expensive products\n",
    "fig=px.histogram(ecommerce_data_orders[ecommerce_data_orders['price_category'] == 'very expensive'],\n",
    "                 x='quantity', \n",
    "                 title='Distribution of quantity of very expensive products')\n",
    "fig.update_layout(xaxis_title='Quantity', yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c354e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_data_orders.to_csv('ecommerce_data_orders.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d160d585",
   "metadata": {},
   "source": [
    "This category is the smallest, only 2581 units were sold, the absolute majority - 1950 in only one copy, much less in 2. Maximum value is 125. There is no such tendency to buy very expensive products in big amount."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd941ea3",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf74f82",
   "metadata": {},
   "source": [
    "We checked what combinations of goods are popular among customers using an Apriori algorithm and found mostly orders of similar products that differ by color or design. We also analyzed what category of products is most popular to orders of many units together and found that very cheap products are absolute leaders here - the most common quantity is 12 units per order. There are much fewer sold products of the rest categories and the most common quantity for them is 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274e2830",
   "metadata": {},
   "source": [
    "## Analysis of canceled orders <a class=\"anchor\" id=\"canceled\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724a2af7",
   "metadata": {},
   "source": [
    "In this section we'll calculate a share of canceled orders, average sum, and define what products often canceled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44afaaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_data_canceled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c0373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the number of canceled orders\n",
    "num_canceled = ecommerce_data_canceled['invoice_no'].nunique()\n",
    "print('Number of canceled orders: {}'.format(num_canceled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the total number of orders\n",
    "num_orders= ecommerce_data['invoice_no'].nunique()\n",
    "print('Total number of orders: {}'.format(num_orders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f6a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating a share of canceled orders\n",
    "share = num_canceled / num_orders * 100\n",
    "print('Share of canceled orders: {:.2f}%'.format(share))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e4ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the total price of each product\n",
    "ecommerce_data_canceled['total_price'] = ecommerce_data_canceled['unit_price'] * (-1) * ecommerce_data_canceled['quantity'] \n",
    "ecommerce_data_canceled = ecommerce_data_canceled.round({'total_price': 2})\n",
    "ecommerce_data_canceled.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf54b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating total sum of the order per customer\n",
    "total_canceled_order=ecommerce_data_canceled.groupby(['customer_id', 'invoice_no'])['total_price'].sum().reset_index()\n",
    "total_canceled_order = total_canceled_order.rename(columns={'total_price': 'total_sum'})\n",
    "total_canceled_order = total_canceled_order.sort_values(by='total_sum', ascending=False)\n",
    "total_canceled_order.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf4cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_canceled_order['total_sum'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78959cef",
   "metadata": {},
   "source": [
    "There are few significant outliers, customer 16446 we already known from searching of total sum of order per customer and this is the same number so he doesn't enter to our analysis. The same thing with the customer 12346. Customer 15749 we saw with one of the biggest average check so he is also out of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21cb9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a histogram of distribution of canceled orders by total sum\n",
    "fig=px.histogram(total_canceled_order[total_canceled_order['total_sum'] < 9000], x='total_sum', \n",
    "                 title='Distribution of canceled orders by total sum')\n",
    "fig.update_layout(xaxis_title='Total sum', yaxis_title='Count')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26e652a",
   "metadata": {},
   "source": [
    "We see that there are few canceled oreders on very big sum in range 100-9000, but the absolute majority (2069) are orders on sum less than 20. Calculating the average sum of canceled order here doesn't make sense, but we can calculate mode to define the most common sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mode of total sum of canceled orders: {}'.format(\n",
    "    total_canceled_order['total_sum'].mode()[0]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103ff3c0",
   "metadata": {},
   "source": [
    "Now we want to find products that were frequently canceled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5081b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge total_sum to df with canceled orders\n",
    "ecommerce_data_canceled= ecommerce_data_canceled.merge(total_canceled_order, on=['customer_id', 'invoice_no'])\n",
    "ecommerce_data_canceled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df478cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what products often canceled?\n",
    "ecommerce_data_canceled['description'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad823b7",
   "metadata": {},
   "source": [
    "'REGENCY CAKESTAND 3 TIER' was in 180 canceled orders that quite big number, but there is big different between it to the 2d place - 87 cancelations of 'JAM MAKING SET WITH JARS'. These goods were in canceled orders, so we can't check if there are any problem with them specifically because there are many possible reasons to cancel the whole order. But we can say that there are relatively not too much cancelations, but reasons should be checked to reduce them more. Probably we have a problem on a page with a confirmation of order?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d76f7",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b46a296",
   "metadata": {},
   "source": [
    "The share of canceled orders is 14.35% which is quite many. There is a wide range of total sums of canceled orders with few significant outliers which seems like a mistake, probably these customers didn’t want to do an order at all. The majority of the canceled orders are within 20, the most common sum is 4.95(we didn’t calculate an average sum because of the too big spread of values). We checked what products are often canceled and found that ‘REGENCY CAKESTAND 3 TIER’ was canceled the most times - 180, and on the 2d place 'JAM MAKING SET WITH JARS', there is significant difference between these number and after that they continue to decrease quickly. We can't say why these products were in canceled orders, but possible reasons of cancelations of whole orders should be checked,probably it's relate to any technical issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7388f6a",
   "metadata": {},
   "source": [
    "## Testing statistical hypotheses <a class=\"anchor\" id=\"hypotheses\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d02ab4",
   "metadata": {},
   "source": [
    "Finally we want to test two statistical hypotheses: \n",
    "1. If there is a statistically significant difference between revenue from small products that were bought in big amounts and big expensive products that bought one at a time?\n",
    "2. If there is a statistically significant difference between revenue in summer and winter?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632070b5",
   "metadata": {},
   "source": [
    "#### First hypothesis <a class=\"anchor\" id=\"first\"></a>\n",
    "First of all we are going to define samples for testing. We will use our previously defined categories of products 'very cheap' and 'very expensive' that perfectly fit our conditions. Customers usually buy multiple units of products from category 'very cheap' and only one at time from category 'very expensive'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ffb50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the data by category and price to find unique products per category and price\n",
    "grouped_category=ecommerce_data_orders.groupby(['price_category', 'total_price'])['description_cleaned'].unique().reset_index()\n",
    "grouped_category.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc8a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking a samples from grouped data\n",
    "very_cheap=grouped_category[grouped_category['price_category'] == 'very cheap']['total_price']\n",
    "print('Size of sample with cheap products: {}'.format(very_cheap.shape[0]))\n",
    "very_expensive=grouped_category[grouped_category['price_category'] == 'very expensive']['total_price']\n",
    "print('Size of sample with expensive products: {}'.format(very_expensive.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a003b37",
   "metadata": {},
   "source": [
    "Before the testing of our hypothesis we need to check samples for normality of distribution. We will do it by using Q-Q plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de410d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the quantile-quantile probability plot\n",
    "z = (very_cheap-np.mean(very_cheap))/np.std(very_cheap)\n",
    "\n",
    "stats.probplot(z, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Probability Plot of 'very_cheap' sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa613cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining an outlier that can corrupt the result of the test\n",
    "print(\"The maximum value of 'very_cheap' sample: {}\".format(very_cheap.max()))\n",
    "print(\"Index of the maximum value: {}\".format(very_cheap.idxmax()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eb8c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the outlier\n",
    "very_cheap=very_cheap.drop(index=[4458])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416cc6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The maximum value of 'very_cheap' sample: {}\".format(very_cheap.max()))\n",
    "print(\"Index of the maximum value: {}\".format(very_cheap.idxmax()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4269e7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the outlier\n",
    "very_cheap=very_cheap.drop(index=[4457])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9fb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the quantile-quantile probability plot\n",
    "z = (very_cheap-np.mean(very_cheap))/np.std(very_cheap)\n",
    "\n",
    "stats.probplot(z, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Probability Plot of 'very_cheap' sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1a2392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the quantile-quantile probability plot\n",
    "z = (very_expensive-np.mean(very_expensive))/np.std(very_expensive)\n",
    "\n",
    "stats.probplot(z, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Probability Plot of 'very_expensive' sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900c8958",
   "metadata": {},
   "source": [
    "This sample is not follow a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618ab926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining an outlier that can corrupt the result of the test\n",
    "print(\"The maximum value of 'very_expensive' sample: {}\".format(very_expensive.max()))\n",
    "print(\"Index of the maximum value: {}\".format(very_expensive.idxmax()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6999544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the outlier\n",
    "very_expensive=very_expensive.drop(index=[4620])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e72ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the quantile-quantile probability plot\n",
    "z = (very_expensive-np.mean(very_expensive))/np.std(very_expensive)\n",
    "\n",
    "stats.probplot(z, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Probability Plot of 'very_expensive' sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8045fa2",
   "metadata": {},
   "source": [
    "The sample is not follow the normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597947a5",
   "metadata": {},
   "source": [
    "Because of data is not distributed normally we will use 'Mann-Whitney U Test'.\n",
    "\n",
    "H0: There are statistical insignificant differences between the average revenue from very cheap and very expensive products.\n",
    "\n",
    "Ha: There are statistical significant differences between the average revenue from very cheap and very expensive products.\n",
    "\n",
    "Level of statistical significance we will use is 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af4932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "results = mannwhitneyu(very_cheap, very_expensive)\n",
    "print('p-value:', results.pvalue)\n",
    "if results.pvalue < alpha:\n",
    "    print('We reject the null hypothesis')\n",
    "else:\n",
    "    print(\"We can't reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e09000",
   "metadata": {},
   "source": [
    "Result of the test is rejecting of the null hypothesis - average revenues from cheap and expensive products are significantly different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d879f38",
   "metadata": {},
   "source": [
    "#### Second Hypothesis <a class=\"anchor\" id=\"second\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67cd47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping winter data to get total sum of order\n",
    "total_order_winter=demand_winter.groupby(['invoice_no'])['total_price'].sum().reset_index()\n",
    "total_order_winter = total_order_winter.rename(columns={'total_price': 'total_order'})\n",
    "total_order_winter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d7b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping summer data to get total sum of order\n",
    "total_order_summer=demand_summer.groupby(['invoice_no'])['total_price'].sum().reset_index()\n",
    "total_order_summer = total_order_summer.rename(columns={'total_price': 'total_order'})\n",
    "total_order_summer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5652d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining sizes of samples\n",
    "print('Size of sample with winter orders: {}'.format(total_order_winter.shape[0]))\n",
    "print('Size of sample with summer orders: {}'.format(total_order_summer.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61e6ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a histogram for the summer sample to define normality of distribution\n",
    "plt.hist(total_order_summer['total_order'], bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b171449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining an outlier that can corrupt the result of the test\n",
    "print(\"The maximum value of summer sample: {}\".format(total_order_summer['total_order'].max()))\n",
    "print(\"Index of the maximum value: {}\".format(total_order_summer['total_order'].idxmax()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c2760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the outlier\n",
    "total_order_summer=total_order_summer.drop(index=[471])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d502ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a new histogram\n",
    "plt.hist(total_order_summer['total_order'], bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b445ce",
   "metadata": {},
   "source": [
    "The data is not distributed normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a625fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a histogram of the winter sample to define normality of distribution\n",
    "plt.hist(total_order_winter['total_order'], bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d6496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining an outlier and its index\n",
    "print(\"The maximum value of winter sample: {}\".format(total_order_winter['total_order'].max()))\n",
    "print(\"Index of the maximum value: {}\".format(total_order_winter['total_order'].idxmax()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f19c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the outlier\n",
    "total_order_winter=total_order_winter.drop(index=[1839])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd831c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a new histogram\n",
    "plt.hist(total_order_winter['total_order'], bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75cea4",
   "metadata": {},
   "source": [
    "The data is not distributed normally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d42e9a",
   "metadata": {},
   "source": [
    "Because of data is not distributed normally we will use 'Mann-Whitney U Test'.\n",
    "\n",
    "H0: There are statistical insignificant differences between the average revenue in summer and winter.\n",
    "\n",
    "Ha: There are statistical significant differences between the average revenue in summer and winter.\n",
    "\n",
    "Level of statistical significance we will use is 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b730e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "results = mannwhitneyu(total_order_winter['total_order'], total_order_summer['total_order'])\n",
    "print('p-value:', results.pvalue)\n",
    "if results.pvalue < alpha:\n",
    "    print('We reject the null hypothesis')\n",
    "else:\n",
    "    print(\"We can't reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e4d8b3",
   "metadata": {},
   "source": [
    "By the result of the test we can't reject the null hypothesis that means that average revenue in summer and winter is not differ significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73cdaf2",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24302fc2",
   "metadata": {},
   "source": [
    "We tested two statistical hypotheses and found out that differences between average revenues from cheap and expensive products are statistically significant, and between average revenues in winter and summer aren't."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b10ec",
   "metadata": {},
   "source": [
    "## Overall Conclusion <a class=\"anchor\" id=\"overall\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f28219",
   "metadata": {},
   "source": [
    "* We got a dataset with 541909 entries that contain information about orders made in the store: order number and date, identifier and name of the product, purchased quantity, price per unit, customer id.\n",
    "* Data was preprocessed: we changed column names and corrected datatypes, removed null values from column ‘description’, filled null values in column ‘customer_id’ with ‘unknown’, removed duplicates. Strange irrelevant values in column ‘stock_code’ were deleted. Dataset was split into two - canceled orders in the separate dataset.\n",
    "* We analyzed prices and defined 4 categories of products by price: 'very cheap' - 0.04-2.12, 'cheap' - 2.13 - 5, 'expensive'- 5-20, ‘very expensive' - 20-650. We also extracted keywords from descriptions and formed 11 categories of products: ‘accessories’, ‘bags’, ‘bathroom’, ‘cabinet’, ‘garden’, ‘hallway’, ‘home decoration’, ‘kitchen’, ‘party’, ‘toys and hobbies’ and ‘other’. \n",
    "* We found out that the most common number of orders per customer is 1. The most customers are regular - 2829 and 1505 made order once.\n",
    "* We categorized customers by the average check: 1- 3.75-350, 2- 350-800, and 3 - 800-85000. The first category is the biggest and we conclude that it’s more common to make small orders, but huge sums of the third group should be noticed. We checked if there is a tendency among customers who made many orders(loyal) to make big orders and there is no such.\n",
    "* We analyzed the seasonality of demand and found out that there are peaks in April and November, most likely related to Easter and Christmas. The popularity of categories is stable throughout the year and proportional during the peaks. There are few patterns of the popularity of certain products by season, such as in summer jambo and lunch bags are at the top of popular goods, also buntings, in spring such bags are popular too, in autumn customers already buy things related to Christmas and in winter more home decorations and kitchen stuff. \n",
    "* We checked what combinations of goods are popular among customers and found mostly orders of similar products that differ by color or design. We also analyzed what category of products is most popular to orders of many units together and found that very cheap products are absolute leaders here - the most common quantity is 12 units per order. There are much fewer sold products of the rest categories and the most common quantity for them is 1.\n",
    "* Analysis of canceled orders showed that the share of canceled orders is  14.35% which is quite many. With the information that we have, we can’t check what it caused by so it should be checked, probably we can reduce this number. \n",
    "* We also tested two statistical hypotheses and found out that differences between average revenues from cheap and expensive products are statistically significant, and between average revenues in winter and summer aren't.\n",
    "\n",
    "Thus we can conclude that studied indicators are good: \n",
    "- we had 4334 customers this year and 2829(65%) made more than 1 order so they are loyal and possibly will return in the future, we need to attract them with special promotions, emails, exclusive offers for buying the same products, etc.\n",
    "- we have a very perspective category of ‘very cheap’ products with prices 0.04-2.12, we sold 280011 such units, we can increase these sales by adding more similar goods and special offers for orders in big amount. Products of the category ‘very expensive’ should be checked, maybe the most expensive ones less suitable for our store or we oppositely should expand this category.\n",
    "- we had significant peaks of demand in Easter and Christmas because we sell a lot of stuff for holidays. We can make a sale with special offers in these periods, we can add more goods related to parties and specific holidays to even increase these peaks. \n",
    "- the amount and sums of canceled orders is not crucial, but still, we can reduce it by checking the possible reasons and if it depends on us - fix it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
